---
title: OS
categories:
  - etc
tags:
  - etc
date: 2019-10-09T13:00:00+09:00
toc: false
use_math: true
---

## Processes

### Process를 이루는 각 메모리 영역

![](https://i.imgur.com/Y7WbZfp.png)

* text(code) : 프로그램 코드, 즉 실제 코드가 기술되는 곳
* data : 전역변수, static 변수, 상수 등이 저장되는 곳. 프로세스가 종료되지 않는 이상 사라지지 않는다.
* stack : 파라미터, 로컬 변수 등 프로그램 수행 과정중에 사용되는 메모리 장소
* heap ; 프로그래머가 할당하는 메모리 장소. 즉 동적 할당이 이루어 지는 장소

### Context Switching

* CPU를 점유하고 있던 프로세스가 할당된 시간을 다 사용한 후 새로운 프로세스로 교체되는 과정
* CPU는 교체할 떄 이전 프로세스의 상태를 저장하고 새로운 프로세스의 상태를 로드해야한다.
* 따라서 저장하고 로드할동안 시스템은 아무것도 할 수 없으므로 오버헤드가 발생한다.

### Process Termination

![](https://i.imgur.com/ifdj2iA.png)

* 연쇄적 종료 : parent 프로세스가 종료되면 child 프로세스도 다 종료되어야 한다
* zombie : 부모가 아직 wait하지 않았는데 자식이 죽었다. 그때 자식은 좀비 프로세스가 된다. 부모가 wait할때 까지 자식은 좀비상태가 된다
* orphan: 자식이 먼저 죽는 것이 일반적인데 부모가 먼저 죽었다. 그 때 자식을 orphan, 고아라고 한다. 모든 프로세스는 부모가 있어야 하므로 고아가 되면 커널이 부모를 만들어 준다. 일반적으로 pid 1번인 init 프로세스가 부모가 되어준다.

### Producer-Consumer Problem

* Communication model

  ![](https://i.imgur.com/mUr12Vm.png)

  * 프로세스는 서로의 공간에 접근이 불가능하다. 따라서 프로세스간 메시지를 주고 받기 위해 위와 같은 방법을 사용한다.

* Shared Memory

  ![](https://i.imgur.com/eGP3XFC.png)

  * 생산자-소비자 문제는 여러개의 프로세스를 어떠헥 동기화할 것인가에 대한 문제이다
  * 생산자는 물건이 만들어지면 버퍼에 저장한다. 이 때 저장할 공간이 없는 문제가 발생할 수 있다.
  * 소비자는 물건이 필요할 때 버퍼에서 물건을 소비한다. 이 떄 소비할 물건이 없는 문제가 발생할 수 있다.
  * 이를 해결하기 위해 동기화 기법의 세마포어를 이용할 수 있다.

### Synchronization

* 메시지 전달은 블로킹과 넌브로킹으로 이루어질 수 있다.
* Blocking
  * synchronous를 고려한 것이다.
  * 보낼려고 하는데 아직 안받았으면 상대가 받을 때까지 대기한다. (Blocking)
  * 메시지를 받으려고 하는데 받을 메시지가 없으면 대기한다. (Blocking)
* Non-blocking
  * asynchronous를 고려한 것이다
  * 상대가 받든 말든 던져놓고 계속 자기 할 일을 한다.
  * 메시지가 있으면 받고 없으면 null처리하고 할 일을 한다.

## Threads

### Process & Thread

- 프로세스 : 운영체제에서 실행중인 하나의 프로그램 (하나 이상의 쓰레드를 포함한다)

- 쓰레드 : 프로세스 내에서 동시에 실행되는 독립적인 실행 단위
  
  ![](https://i.imgur.com/FzGsj0S.png)
  
  - 장점
    - 멀티 쓰레드를 구현하게 되면 예를 들어 하나의 쓰레드가 I/O작업으로 block이 된다고 하더라도 다른 쓰레드는 일을 할 수 있기에 응답성이 좋아진다.
    - 메모리와 리소스를 공유할 수 있고 이로 인해 컨텍스트 스위칭이 일어날 때 오버헤드가 작다.
  - 단점
    - 데드락이 발생할 수 있다.
  
- 즉 프로세스는 운영체제에서 실행되고 있는 하나의 프로그램이고 그 프로세스 내에서 실행되는 각각의 일을 쓰레드라고 한다.

- 쓰레드는 프로세스의 대부분의 자원을 공유하지만 자신만의 실행 스택을 가진다.

## CPU Scheduling

### CPU scheduler

* 프로세스들 중에서 실행할 준비가 되어있는 프로세스를 선택해준다

  ![](https://i.imgur.com/GVPOqIw.png)

  1. I/O request나 이벤트가 일어날 경우 running에서 waiting으로 프로세스가 스위치된다
  2. 자신에게 할당된 시간이 다 된 경우 running상태에서 ready상태로 프로세스가 스위치된다
  3. I/O작업이나 이벤트가 완료되었을 경우 waiting상태에서 readty상태로 프로세스가 스위치된다
  4. 프로세스가 종료된다.

* 1번이나 4번의 경우는 non-preemptive, 자발적으로 중단이 된다.

* 2번이나 3번의 경우는 preemptive. 강제로 중단된다.

* 3번의 경우는 I/O작업은 CPU 자원을 그리 많이 안먹고, I/O이벤트에 대한 반응은 즉각적으로 해 줄 필요가 있으므로 수행되고 있는 프로세스가 있더라도 강제로 중단하고 먼저 실행할 수 있도록 스케쥴링 해 준다.

### Dispatcher

* 선택된 프로세스에게 CPU 제어권을 준다.
* 기존에 실행하던 프로세스의 상태를 저장 후 ready로 보내고 실행할 프로세스를 로드한다. (context swithcing)

### Scheduling Algorithms

* **First-Come First-Served(FCFS)**

  ![](https://i.imgur.com/lCuIsVk.png)

  * 먼저 온 프로세스를 먼저 처리한다.
  * FCFS는 non-preemptive, 즉 중간에 중단되지 않는다.
  * 어느 프로세스가 먼저오느냐에 따라 평균 대기 시간의 편차가 심하다.

* **Shortest-Job-First(SJF)**

  * 가장 CPU를 짧게 사용하는 프로세스를 먼저 처리한다.

  * 평균 대기 시간이 상당히 놓다. 하지만 현실적으로 어느 프로세스가 CPU를 먼저 처리할 지 알 수 없으므로 추정 기법을 사용한다.

  * SJF에는 두가지 종류가 있다.

    * Non-Preemptive SJF

      ![](https://i.imgur.com/0y3PJys.png)

    * Preemptive SJF

      * 프로세스가 들어오는 순간에 계산을 다시해서 짧은 시간을 먼저 실행한다.

      ![](https://i.imgur.com/RllXRaf.png)

  * **Priority Scheduling**

    * 각 프로세스에 우선순위를 둔다.
    * 우선순위가 높은 프로세스가 다 끝나야 다음 프로세스가 실행된다.
    * SJF도 일종의 우선순위 스케쥴링이다. CPU 사용 시간이 우선순위가 된다.
    * 이로 인해 Starvation(기아, 결핍)이 발생할 수 있다. 즉 우선순위가 낮은 프로세스가 영원히 실행되지 않을 수 있다.
    * 이를 해결하기 위해 Aging을 시용한다. 즉 기다릴때마다 우선 순위를 높여준다.

  * **Round Robin(RR)**

    * 일반적으로 가장 많이 사용하는 방식이다

    * CPU 타임을 일정한 타임 간격으로 나누어서 해당 시간이 경과되면 실행되던 프로세스는 CPU 점유를 빼앗기고 ready 큐의 맨 마지막으로 간다.

    * 타임 간격, q가 클수록 FCFS에 가까워지고 q가 작을수록 context switching이 극도로 자주 일어나기에 오버헤드가 발생한다.

      ![](https://i.imgur.com/BTfQN5Y.png)

    * 일반적으로 turnaround time(request했던 시간과 최종적으로 완료가 되었을 때까지 걸린 시간)은 늦지만 반응시간이 빠르다.

  * **Multilevel Queue**

    * 여러개의 큐를 두고 foreground queue에는 반응 시간이 빨라야 하는 프로세스를, background queue에는 완료되기만 하면 되는 프로세스(배치 프로세스)를 실행한다.
    * 즉 foreground에는 RR을, background에는 FCFS를 사용해도 된다.

## Synchronization

### Race Condition

* 여러개의 프로세스가 CPU 또는 Resource를 할당받기 위한 경쟁 상태를 뜻한다
* 프로세스의 동기화 기법으로 해결이 가능하다.

### Critical Section Problem

![](https://i.imgur.com/aZw2r4J.png)

* 임계 구역은 shared data에 액세스 하는 코드 부분을 뜻한다.
* 공유 데이터에 둘 이상의 임계 구역이 들어가게 되면 원치 않은 결과가 나올 수 있다. 따라서 동시에 접근하는 것을 막아야 한다.

### Semaphore

![](https://i.imgur.com/pN7I4n2.png)

* 세마포어는 일반적인 int 변수이다

* 이 변수가 0이면 대기하고 0보다 크면 빠져나온다

* 만약 화장실이 있는데 열쇠가 4개라면 4명까지는 대기없이 바로 사용할 수 있고 그 다음부턴 열쇠가 없으니 열쇠가 생길 때 까지 대기해야한다.

  ![](https://i.imgur.com/zDBGiai.png)

### Mutex

![](https://i.imgur.com/7VE2lPq.png)

* 뮤텍스는 세마포어가 0 또는 1의 값만 가질 경우. 바이너리 세마포어이다.
* 즉 열쇠가 하나밖에 없는 경우 뮤텍스이다.
* 상호 배제를 제공한다.

### Problem

* 이러한 동기화 기법을 이용해 한계가 있는 버퍼 문제를 해결할 수 있다.

  * Producer-Consumer Problem

    ![](https://i.imgur.com/QrZnsKB.png)

  * Readers-Writers Problem

    ![](https://i.imgur.com/6H6BEjY.png)

* 하지만 Dining-Philosophers Problem이 발생 할 수 있다.

  ![](https://i.imgur.com/OAoGIZW.png)

  * 즉 데드락이 발생할 수 있다는 문제점을 가진다.

## Deadlocks

### Deadlock

![](https://i.imgur.com/JqsRLv5.png)

* 데드락은 다음과 같은 예를 들어 설명할 수 있습니다. P0쓰레드가 S라는 공유 변수에 락을 걸어둔 상태로 작업을 진행하고 있고, P1쓰레드가 Q라는 공유 변수에 락을 걸어둔 상태로 작업을 진행하고 있다고 가정합니다. 여기서 P0쓰레드에서 Q공유 변수가 필요한 코드를 만났지만 Q는 이미 P1쓰레드가 선점하고 있으므로 P0쓰레드는 대기 상태로 변경됩니다. 동시에 P1쓰레드에서도 S공유 변수가 필요한 코드를 만났다고 가정하면 S는 이미 P0쓰레드가 선점하고 있으므로 b쓰레드도 역시 대기 상태로 변경됩니다. 이렇게 두 쓰레드가 모두 대기 상태에 머무르게 되는 현상을 말합니다.

### Deadlock의 발생조건

* **Mutual exclusion**

  * 상호 배제
  * 리소스를 하나의 프로세스만 사용할 수 있다

* **Hold and wait**

  * 하나는 가지고 있고 하나를 기다린다. 기다리고 있는 건 그 전에 다른 프로세스가 가지고 있다

* **No preemption**

  * 자발적으로 릴리즈해야만 사용할 수 있다. 강제로 빼앗을 수 없다.

* **Circular wait**

  ![](https://i.imgur.com/Ki4NsHD.png)

  * 프로세스들이 존재할때 원형을 이루면서 hold & wait 상태를 가진다

* 위 네가지를 모두 만족해야 Deadlock이 일어난다.

### Deadlock 핸들링 방법

* 데드락을 예방한다
  * 네가지 조건을 모두 만족해야 데드락이 일어나므로 하나라도 일어나지 않도록 예방한다.
  * 단, 상호 배제는 일어나지 않을 수가 없으므로 배제한다.
  * 가지고자 하는 리소스를 모두 가져야만 실행하도록 하거나(wait하지 않는다.), 한 개를 가지고 실행하다가 다른 하나를 요구했을 때 즉각적으로 가지지 못하면 모두 릴리즈를 하거나, 서클이 일어나지 않도록 서로 정렬된 순서대로 요구하도록 한다.
* 그 외 데드락을 피해가거나 데드락이 일어났을 경우 데드락을 탐지해서 복구하도록 한다.

## Main Memory

### Memory Management Unit (MMU)

* 로지컬 주소를 피지컬 주소로 매핑해주는 역할을 하는 하드웨어이다.
* relocation register값에 로지컬 주소를 더해서 매핑시켜준다.

### 메모리 할당 전략

* First-fit : 프로세스가가 들어갈 수 있는 충분한 공간 중 첫번째 홀에 할당
* Best-fit : 프로세스가 들어갈 수 있는 공간 중 가장 작은 홀에 할당. 
* Worst-fit : 프로세스가 들어갈 수 있는 공간 중 가장 큰 홀에 할당.

### 메모리 할당에서의 문제점

![](https://i.imgur.com/zmoL7Z6.png)

* 외부 단편화
  * 들어갈 수 있는 전체 공간은 만족하지만 단편화 때문에 공간이 연속적이지 않은 경우
  * 따라서 빈 공간을 모으기 위해 실행되고 있는 프로세스를 한쪽으로 몰아야 하기에 오버헤드가 발생한다.
* 내부 단편화
  * 할당되는 메모리가 필요로 하는 메모리보다 약간 더 커서 작은 공간이 생기는 경우

### 메모리 단편화 기술 - Paging

* 보조기억장치를 이용한 가상 메모리를 같은 크기의 블록으로 나눈 것을 페이지라 하고 실제 메모리를 페이지와 같은 크기로 나눈 것을 프레임이라 할 때,
* 페이징 기법은 필요할 때 해당 페이지를 프레임으로 옮겨 사용하는 방법.
* 페이지와 프레임을 매핑시키기 위한 페이지 테이블이 필요하다
* 페이징 기법을 이용하면 연속적이지 않은 공간도 활용할 수 있으므로 외부 단편화 문제를 해결할 수 있다
* 하지만 페이지 단위를 알맞게 꽉 채워 쓰는것이 아니므로 내부 단편화 문제는 여전하다.

### 메모리 단편화 기술 - Segmentation

* 세그먼테이션에서는 가상 메모리를 서로 크기가 다른 논리적 단위인 세그먼트로 나누어 메모리에 할당한다.
* 마찬가지로 매핑을 위해 세그먼트 테이블이 필요하다
* 프로세스가 필요한 메모리만큼 할당해 주기에 내부 단편화는 일어나지 않지만 외부 단편화 문제가 존재한다.

### 메모리 단편화 기술 - Memory Pool

* 필요한 메모리 공간을 필요한 크기, 갯수만큼 사용자가 직접 지정해서 미리 할당받아놓고 필요할 때마다 사용하고 반납하는 기법
* 필요한 공간만큼 미리 할당해놓고 쓰고 반납하기에 외부 단편화와 내부 단편화 모두 생기지 않는다.
* 하지만 미리 할당해놓고 사용하지 않는 동안 메모리 누수가 발생한다.

## Virtual Memory

### Page Fault

![](https://i.imgur.com/DKoavuV.png)

* 메인메모리에 할당되지 않은 페이지에 접근할 때 page fault가 발생한다.
* 먼저 주소를 체킹한다. 주소 자체가 잘못되었거나 권한이 없어 사용할 수 없을 경우 비정상적 종료를 일으킨다.
* 만약 디스크 내부에 존재하면 빈 프레임을 찾는다. 빈 프레임이 없을 경우 페이지 교체 정책에 따라 빈 곳을 만든다.
* I/O 작업을 통해 새로운 페이지를 불러오고 완료가 되면 ready queue로 넣은 다음 프로세스를 재시작한다.

### Page Replacement - FIFO

![](https://i.imgur.com/pMRci1N.png)

* 먼저 메모리에 들어 온 것이 먼저 나간다. (First In First Out)

### Page Replacement - LRU

![](https://i.imgur.com/pMRci1N.png)

* 가장 최근에 사용되지 않은 페이지를 내보낸다. (Least Recently Used)
* 최근에 사용된 페이지는 가까운 미래에 또 볼 것이라고 예상
* 최근에 사용된 페이지 체킹 방법
  * Counter : 각 페이지마다 카운터를 두고 참조할 때마다 카운터를 증가시킨다. 즉 카운터 값이 가장 작은 것을 교체한다.
  * Stack : 스택을 두고 참조될 때마다 맨 위로 올린다. 따라서 제일 위에 있는 것이 가장 최근에 사용한 것이므로 굳이 찾을 필요가 없다.

### Thrashing

* 내가 자주 참조하는 페이지보다 실제 메모리 사이즈가 더 작을 경우 page fault가 높아져 디스크에서 해당 페이지를 가져오는데 시간이 더 걸리므로 CPU 사용률이 급격히 떨어지게 된다.
* page fault 비율이 높아지면 프레임을 더 할당해준다.

## Secondary Storage

### FCFS (First Come First Served)

### SSFT (Shortest Seek Time FIrst)

### SCAN

### C-SCAN

### C-LOOK

## I/O Systems

### Polling

* 폴링은 OS가 계속 순찰을 돌면서 I/O가 완료되었는지 체킹한다
* 각 I/O디바이스에는 자기의 상태를 나타내는 레지스터가 있으므로 주기적으로 OS가 체킹한다.

### Interrupt

* I/O 디바이스가 직접 완료되었다, 서비스가 필요하다고 OS에 알린다

## 기타

### 32비트 CPU와 64비트의 차이

* 32bit 컴퓨터 cpu의 레지스터 처리값은 32bit, 64bit 컴퓨터 cpu의 레지스터 처리값은 64bit이다.

* 레지스터는 cpu가 사용하는 데이터를 담는 그릇이고 cpu는 레지스터를 이용해서 데이터를 처리한다. 따라서 32비트 컴퓨터와 64비트 컴퓨터는 컴퓨터 설계부터 이렇게 이용하는 레지스터 그릇의 값이 차이가 난다.

* 32비트 컴퓨터는 한번에 처리할 수 있는 용량이 32비트이므로 한번에 표현가능한 수의 최댓값은 ${2}^{32}$이 된다. 레지스터가 한번에 표현할 수 있는 값의 크기는 cpu가 한번에 인식하여 처리할 수 있는 주소 값의 범위가 되므로 32비트 컴퓨터는
  $$
  {2}^{32} = 2^{2}\times2^{30} = 4GB
  $$
  최대 4GB의 메모리만 인식할 수 있다.

* 64비트 컴퓨터는 마찬가지로
  $$
  {2}^{64} = 2^{4}\times2^{60} = 16EB
  $$
  최대 16엑사바이트만큼 메모리를 인식할 수 있다.